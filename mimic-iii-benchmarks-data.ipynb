{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4960aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-30T16:58:59.848220Z",
     "iopub.status.busy": "2024-08-30T16:58:59.847710Z",
     "iopub.status.idle": "2024-08-30T16:59:00.322513Z",
     "shell.execute_reply": "2024-08-30T16:59:00.321277Z"
    },
    "papermill": {
     "duration": 0.483918,
     "end_time": "2024-08-30T16:59:00.325403",
     "exception": false,
     "start_time": "2024-08-30T16:58:59.841485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cd6b6",
   "metadata": {
    "papermill": {
     "duration": 0.003041,
     "end_time": "2024-08-30T16:59:00.332059",
     "exception": false,
     "start_time": "2024-08-30T16:59:00.329018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This note shows how to build benchmark with MIMIC-III data.  For more informations, please refer to github repo https://github.com/YerevaNN/mimic3-benchmarks.git.  There will be few codes in this note. \n",
    "\n",
    "\n",
    "## Environment prepare\n",
    "\n",
    "Suggested to use Miniconda to create environment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5313a16e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:00.340610Z",
     "iopub.status.busy": "2024-08-30T16:59:00.339992Z",
     "iopub.status.idle": "2024-08-30T16:59:26.013733Z",
     "shell.execute_reply": "2024-08-30T16:59:26.011991Z"
    },
    "papermill": {
     "duration": 25.6811,
     "end_time": "2024-08-30T16:59:26.016434",
     "exception": false,
     "start_time": "2024-08-30T16:59:00.335334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\r\n",
      "Channels:\r\n",
      " - rapidsai\r\n",
      " - nvidia\r\n",
      " - nodefaults\r\n",
      " - conda-forge\r\n",
      "Platform: linux-64\r\n",
      "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n",
      "Solving environment: \\ \b\b| \b\bfailed\r\n",
      "\r\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\r\n",
      "\r\n",
      "  - python=3.7.13*\r\n",
      "\r\n",
      "Current channels:\r\n",
      "\r\n",
      "  - https://conda.anaconda.org/rapidsai\r\n",
      "  - https://conda.anaconda.org/nvidia\r\n",
      "  - https://conda.anaconda.org/nodefaults\r\n",
      "  - https://conda.anaconda.org/conda-forge\r\n",
      "\r\n",
      "To search for alternate channels that may provide the conda package you're\r\n",
      "looking for, navigate to\r\n",
      "\r\n",
      "    https://anaconda.org\r\n",
      "\r\n",
      "and use the search bar at the top of the page.\r\n",
      "\r\n",
      "\r\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda create -n \"mimic3\" python=3.7.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9dfcaa",
   "metadata": {
    "papermill": {
     "duration": 0.006171,
     "end_time": "2024-08-30T16:59:26.029016",
     "exception": false,
     "start_time": "2024-08-30T16:59:26.022845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Question:  Is it really need to use pyhon 3.7?  The following errors are caused by lib version controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c3fdd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:26.044755Z",
     "iopub.status.busy": "2024-08-30T16:59:26.044252Z",
     "iopub.status.idle": "2024-08-30T16:59:28.889227Z",
     "shell.execute_reply": "2024-08-30T16:59:28.887747Z"
    },
    "papermill": {
     "duration": 2.855963,
     "end_time": "2024-08-30T16:59:28.892113",
     "exception": false,
     "start_time": "2024-08-30T16:59:26.036150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a366e0",
   "metadata": {
    "papermill": {
     "duration": 0.006204,
     "end_time": "2024-08-30T16:59:28.904890",
     "exception": false,
     "start_time": "2024-08-30T16:59:28.898686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here are the requirements.txt\n",
    "\n",
    "Keras==2.1.2\n",
    "tensorflow==1.15.0\n",
    "protobuf==3.19.0\n",
    "pandas==1.2.5\n",
    "scikit-learn==1.0.2\n",
    "numpy==1.16.5\n",
    "pyyaml==6.0\n",
    "tqdm\n",
    "\n",
    "Expected errors:\n",
    "\n",
    "ERROR: Could not find a version that satisfies the requirement tensorflow==1.15.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0)\n",
    "ERROR: No matching distribution found for tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f532b",
   "metadata": {
    "papermill": {
     "duration": 0.006125,
     "end_time": "2024-08-30T16:59:28.917487",
     "exception": false,
     "start_time": "2024-08-30T16:59:28.911362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get MIMIC-III data\n",
    "\n",
    "There are no instructions in github repo for getting MIMIC-III data. Assume this canbe downloaded from https://mimic.mit.edu/docs/iii/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39d069",
   "metadata": {
    "papermill": {
     "duration": 0.006066,
     "end_time": "2024-08-30T16:59:28.929984",
     "exception": false,
     "start_time": "2024-08-30T16:59:28.923918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmarking data\n",
    "\n",
    "Since there are issues of pip install, the following code can not be verified. \n",
    "\n",
    "1. The following command takes MIMIC-III CSVs, generates one directory per `SUBJECT_ID` and writes ICU stay information to `data/{SUBJECT_ID}/stays.csv`, diagnoses to `data/{SUBJECT_ID}/diagnoses.csv`, and events to `data/{SUBJECT_ID}/events.csv`. This step might take around an hour.\n",
    "```bash\n",
    "       python -m mimic3benchmark.scripts.extract_subjects {PATH TO MIMIC-III CSVs} data/root/\n",
    "```\n",
    "\n",
    "2. The following command attempts to fix some issues (ICU stay ID is missing) and removes the events that have missing information. About 80% of events remain after removing all suspicious rows (more information can be found in [`mimic3benchmark/scripts/more_on_validating_events.md`](mimic3benchmark/scripts/more_on_validating_events.md)).\n",
    "```bash\n",
    "       python -m mimic3benchmark.scripts.validate_events data/root/\n",
    "```\n",
    "\n",
    "3. The next command breaks up per-subject data into separate episodes (pertaining to ICU stays). Time series of events are stored in ```{SUBJECT_ID}/episode{#}_timeseries.csv``` (where # counts distinct episodes) while episode-level information (patient age, gender, ethnicity, height, weight) and outcomes (mortality, length of stay, diagnoses) are stores in ```{SUBJECT_ID}/episode{#}.csv```. This script requires two files, one that maps event ITEMIDs to clinical variables and another that defines valid ranges for clinical variables (for detecting outliers, etc.). **Outlier detection is disabled in the current version**.\n",
    "```bash\n",
    "       python -m mimic3benchmark.scripts.extract_episodes_from_subjects data/root/\n",
    "```\n",
    "\n",
    "4. The next command splits the whole dataset into training and testing sets. Note that the train/test split is the same of all tasks.\n",
    "```bash\n",
    "       python -m mimic3benchmark.scripts.split_train_and_test data/root/\n",
    "```\n",
    "\n",
    "5. The following commands will generate task-specific datasets, which can later be used in models. These commands are independent, if you are going to work only on one benchmark task, you can run only the corresponding command.\n",
    "```bash\n",
    "       python -m mimic3benchmark.scripts.create_in_hospital_mortality data/root/ data/in-hospital-mortality/\n",
    "       python -m mimic3benchmark.scripts.create_decompensation data/root/ data/decompensation/\n",
    "       python -m mimic3benchmark.scripts.create_length_of_stay data/root/ data/length-of-stay/\n",
    "       python -m mimic3benchmark.scripts.create_phenotyping data/root/ data/phenotyping/\n",
    "       python -m mimic3benchmark.scripts.create_multitask data/root/ data/multitask/\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.93957,
   "end_time": "2024-08-30T16:59:29.458703",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-30T16:58:56.519133",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
