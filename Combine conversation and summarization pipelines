{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brief introduction of Pipeline\n\nThe pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. \n\n## Conversation  pipeline\n\nConversation pipeline could generate chat reponses based on converstions. In huggingface's introduction (https://huggingface.co/docs/transformers/v4.39.3/en/main_classes/pipelines#transformers.Conversation), the coversation pipeline use transformer.Converation as input class and output, which could help to add new messages and keep the chat history. However, based on my test for transformers=4.39.3, conversation pipeline only takes str and string list as the input. The best ways to input is to convert chats into string by using chat_template.\n","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install transformers==4.39.3\n!pip install accelerate==0.28.0\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T16:18:41.747406Z","iopub.execute_input":"2024-04-11T16:18:41.748032Z","iopub.status.idle":"2024-04-11T16:19:13.193900Z","shell.execute_reply.started":"2024-04-11T16:18:41.747998Z","shell.execute_reply":"2024-04-11T16:19:13.192388Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nchatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")\n# Conversation objects initialized with a string will treat it as a user message\nmessages = \"Why people say Melbourne is a good place to travel?\"\nresponse = chatbot(messages)\n\nprint(response[0].get(\"generated_text\"))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T16:32:22.647703Z","iopub.execute_input":"2024-04-11T16:32:22.648135Z","iopub.status.idle":"2024-04-11T16:32:30.193509Z","shell.execute_reply.started":"2024-04-11T16:32:22.648105Z","shell.execute_reply":"2024-04-11T16:32:30.192297Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":" I've never been, but I've heard it's a great place to visit. It's the capital and most populous city in the United States.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Use summarization to combine results\n\nIn most of the cases, conversations have purpose. The messages with inaccurate information is not what we expected. And also , sometimes we have other technologies to get the more meaningful but less context-related messages. It could be a better solution to combine these two types of messages together. And thankfully , we have the summarization pipeline","metadata":{}},{"cell_type":"code","source":"\nsummarizer = pipeline(\"summarization\")\n\ncorrect_message = \"Melbourne is often considered one of the most livable cities globally, offering a high quality of life.\"\n\ncombined_message = correct_message + response[0].get(\"generated_text\")\n\nsummarizer(combined_message, min_length=5, max_length=50)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T16:36:35.366292Z","iopub.execute_input":"2024-04-11T16:36:35.366910Z","iopub.status.idle":"2024-04-11T16:36:49.113112Z","shell.execute_reply.started":"2024-04-11T16:36:35.366873Z","shell.execute_reply":"2024-04-11T16:36:49.111938Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75fb19dbc4404b5a94ddbedfdec06c3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfdcd21c754f45288aab71cc7a834c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"049f8e12df8c4bd1adb04c99e6945e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b94ad7316b69408d9c9cc120874260d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60b366816d684724acf411f3337f20ee"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \" Melbourne is often considered one of the most livable cities globally . It's the capital and most populous city in the United States .\"}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Limitation of this article\n\nI know Melbourne is not captial of US, it's not even a city of US ! This result means we stil have room to impove our method to have the useful conversations. I believe this would be our next target in the future. ","metadata":{}}]}