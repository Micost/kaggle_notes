{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":194747480,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data extraction based on tasks\n\nThese tasks for evaluating data-science pipeline, more see [paper](#TODO). We focus on two tasks, `binary classification` and `regression` tasks.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"#!pip install --ignore-installed -U -q datasets==2.18.0","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:18.197800Z","iopub.execute_input":"2024-09-09T14:54:18.198424Z","iopub.status.idle":"2024-09-09T14:54:18.204825Z","shell.execute_reply.started":"2024-09-09T14:54:18.198360Z","shell.execute_reply":"2024-09-09T14:54:18.203572Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"DATASET\"] = \"aisuko/mimic_iv_classification_regression_tasks\"","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:59.321843Z","iopub.execute_input":"2024-09-09T14:54:59.322923Z","iopub.status.idle":"2024-09-09T14:54:59.696650Z","shell.execute_reply.started":"2024-09-09T14:54:59.322849Z","shell.execute_reply":"2024-09-09T14:54:59.695302Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Parameters for specific tasks\n\n","metadata":{}},{"cell_type":"code","source":"time=0\ndisease_label=\"No Disease Filter\"\nlabel='mortality'\n\ncohort_output=\"cohort_\" + 'icu' + \"_\" + label + \"_\" + str(time) +\"_\" + disease_label\nsummary_output=\"summary_\" + 'icu' + \"_\" + label + \"_\" + str(time) +\"_\" + disease_label\n\n\ngroup_col='subject_id'\nvisit_col='stay_id'\nadmit_col='intime'\ndisch_col='outtime'\ndeath_col='dod'\nadm_visit_col='hadm_id'\nuse_mort=True,\nuse_los=False\nlos=0\nuse_admn=False\ndisease_label=\"\"\nuse_ICU=True","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:55:02.092645Z","iopub.execute_input":"2024-09-09T14:55:02.093683Z","iopub.status.idle":"2024-09-09T14:55:02.101591Z","shell.execute_reply.started":"2024-09-09T14:55:02.093630Z","shell.execute_reply":"2024-09-09T14:55:02.100048Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"icu_data_path='/kaggle/input/pre-download-mimic-iv-v2-0-dataset/physionet.org/files/mimiciv/2.0/icu/icustays.csv.gz'\nicu_patents_data_path='/kaggle/input/pre-download-mimic-iv-v2-0-dataset/physionet.org/files/mimiciv/2.0/hosp/patients.csv.gz'\nhosp_admissions='/kaggle/input/pre-download-mimic-iv-v2-0-dataset/physionet.org/files/mimiciv/2.0/hosp/admissions.csv.gz'","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:55:05.937124Z","iopub.execute_input":"2024-09-09T14:55:05.937626Z","iopub.status.idle":"2024-09-09T14:55:05.943406Z","shell.execute_reply.started":"2024-09-09T14:55:05.937576Z","shell.execute_reply":"2024-09-09T14:55:05.941971Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Combines the MIMIC-IV core/patients table information with either the icu/icustays or core/admissions data.","metadata":{}},{"cell_type":"code","source":"import polars as pl\n\ndef get_visit_pts(group_col:str, visit_col:str, admit_col:str, disch_col:str, adm_visit_col:str, use_mort:bool, use_los:bool, los:int, use_admn:bool, disease_label:str, use_ICU:bool):\n    # 读取数据\n    visit = pl.read_csv(icu_data_path, compression='gzip', dtypes={admit_col: pl.Datetime, disch_col: pl.Datetime})\n    \n    if use_admn:\n        pts = pl.read_csv(icu_patients_data_path, compression='gzip', usecols=['subject_id', 'dod'], dtypes={'dod': pl.Datetime})\n        visit = visit.join(pts, on='subject_id', how='inner')\n        visit = visit.filter(pl.col('dod').is_null() | (pl.col('dod') >= pl.col(disch_col)))\n        \n        if len(disease_label):\n            hids = disease_cohort.extract_diag_cohort(visit['hadm_id'].to_pandas(), disease_label, mimic4_path)\n            visit = visit.filter(pl.col('hadm_id').is_in(hids['hadm_id'].to_pandas()))\n            print(\"[ READMISSION DUE TO \"+disease_label+\" ]\")\n\n    pts = pl.read_csv(\n        icu_patients_data_path, \n        compression='gzip', \n        usecols=[group_col, 'anchor_year', 'anchor_age', 'anchor_year_group', 'dod', 'gender']\n    )\n    \n    pts = pts.with_columns([\n        (pl.col('anchor_year') - pl.col('anchor_age')).alias('yob'),\n        (pl.col('anchor_year') + (2019 - pl.col('anchor_year_group').str.slice(-4).cast(pl.Int32))).alias('min_valid_year')\n    ])\n    \n    visit_pts = visit.join(pts, on=group_col, how='inner')\n    visit_pts = visit_pts.with_columns([\n        pl.col('anchor_age').alias('Age')\n    ]).filter(pl.col('Age') >= 18)\n    \n    # 添加 Demo 数据\n    eth = pl.read_csv(hosp_admissions, compression='gzip', usecols=['hadm_id', 'insurance', 'race'])\n    visit_pts = visit_pts.join(eth, on='hadm_id', how='inner')\n    \n    return visit_pts.select([group_col, visit_col, adm_visit_col, admit_col, disch_col, 'los', 'min_valid_year', 'dod', 'Age', 'gender', 'race', 'insurance'])\n\n# 调用函数\npts = get_visit_pts(\n    group_col=group_col,\n    visit_col=visit_col,\n    admit_col=admit_col,\n    disch_col=disch_col,\n    adm_visit_col=adm_visit_col,\n    use_mort=use_mort,\n    use_los=use_los,\n    los=los,\n    use_admn=use_admn,\n    disease_label=disease_label,\n    use_ICU=use_ICU\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:19.061210Z","iopub.execute_input":"2024-09-09T14:54:19.061651Z","iopub.status.idle":"2024-09-09T14:54:20.876944Z","shell.execute_reply.started":"2024-09-09T14:54:19.061607Z","shell.execute_reply":"2024-09-09T14:54:20.874528Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     visit_pts\u001b[38;5;241m=\u001b[39m visit_pts\u001b[38;5;241m.\u001b[39mmerge(eth, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m visit_pts[[group_col, visit_col, adm_visit_col, admit_col, disch_col,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_valid_year\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdod\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 35\u001b[0m pts \u001b[38;5;241m=\u001b[39m \u001b[43mget_visit_pts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisit_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisit_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43madmit_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madmit_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisch_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisch_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43madm_visit_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madm_visit_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_mort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_mort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_los\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_los\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_admn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_admn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisease_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisease_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ICU\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ICU\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mget_visit_pts\u001b[0;34m(group_col, visit_col, admit_col, disch_col, adm_visit_col, use_mort, use_los, los, use_admn, disease_label, use_ICU)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_visit_pts\u001b[39m(group_col:\u001b[38;5;28mstr\u001b[39m, visit_col:\u001b[38;5;28mstr\u001b[39m, admit_col:\u001b[38;5;28mstr\u001b[39m, disch_col:\u001b[38;5;28mstr\u001b[39m, adm_visit_col:\u001b[38;5;28mstr\u001b[39m, use_mort:\u001b[38;5;28mbool\u001b[39m, use_los:\u001b[38;5;28mbool\u001b[39m, los:\u001b[38;5;28mint\u001b[39m, use_admn:\u001b[38;5;28mbool\u001b[39m, disease_label:\u001b[38;5;28mstr\u001b[39m,use_ICU:\u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     visit \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43micu_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43madmit_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisch_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_admn:\n\u001b[1;32m      6\u001b[0m         pts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(icu_patents_data_path, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdod\u001b[39m\u001b[38;5;124m'\u001b[39m], parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdod\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:765\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    764\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[1;32m    772\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[1;32m    773\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[1;32m    777\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/pre-download-mimic-iv-v2-0-dataset/physionet.org/files/mimiciv/2.0/icu/icustays.csv.gz'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/pre-download-mimic-iv-v2-0-dataset/physionet.org/files/mimiciv/2.0/icu/icustays.csv.gz'","output_type":"error"}]},{"cell_type":"code","source":"pts.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.877972Z","iopub.status.idle":"2024-09-09T14:54:20.878419Z","shell.execute_reply.started":"2024-09-09T14:54:20.878199Z","shell.execute_reply":"2024-09-09T14:54:20.878220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pts.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.879873Z","iopub.status.idle":"2024-09-09T14:54:20.880351Z","shell.execute_reply.started":"2024-09-09T14:54:20.880131Z","shell.execute_reply":"2024-09-09T14:54:20.880155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extraction columns","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport datetime\n\ndef partition_by_los(df:pd.DataFrame, los:int, group_col:str, visit_col:str, admit_col:str, disch_col:str, valid_col:str):\n    \n    invalid = df.loc[(df[admit_col].isna()) | (df[disch_col].isna()) | (df['los'].isna())]\n    cohort = df.loc[(~df[admit_col].isna()) & (~df[disch_col].isna()) & (~df['los'].isna())]\n    \n    \n    #cohort=cohort.fillna(0)\n    pos_cohort=cohort[cohort['los']>los]\n    neg_cohort=cohort[cohort['los']<=los]\n    neg_cohort=neg_cohort.fillna(0)\n    pos_cohort=pos_cohort.fillna(0)\n    \n    pos_cohort['label']=1\n    neg_cohort['label']=0\n    \n    cohort=pd.concat([pos_cohort,neg_cohort], axis=0)\n    cohort=cohort.sort_values(by=[group_col,admit_col])\n    #print(\"cohort\",cohort.shape)\n    print(\"[ LOS LABELS FINISHED ]\")\n    return cohort, invalid\n\ndef partition_by_readmit(df:pd.DataFrame, gap:datetime.timedelta, group_col:str, visit_col:str, admit_col:str, disch_col:str, valid_col:str):\n    \"\"\"Applies labels to individual visits according to whether or not a readmission has occurred within the specified `gap` days.\n    For a given visit, another visit must occur within the gap window for a positive readmission label.\n    The gap window starts from the disch_col time and the admit_col of subsequent visits are considered.\"\"\"\n    \n    case = pd.DataFrame()   # hadm_ids with readmission within the gap period\n    ctrl = pd.DataFrame()   # hadm_ids without readmission within the gap period\n    invalid = pd.DataFrame()    # hadm_ids that are not considered in the cohort\n\n    # Iterate through groupbys based on group_col (subject_id). Data is sorted by subject_id and admit_col (admittime)\n    # to ensure that the most current hadm_id is last in a group.\n    #grouped= df[[group_col, visit_col, admit_col, disch_col, valid_col]].sort_values(by=[group_col, admit_col]).groupby(group_col)\n    grouped= df.sort_values(by=[group_col, admit_col]).groupby(group_col)\n    for subject, group in tqdm(grouped):\n        max_year = group.max()[disch_col].year\n\n        if group.shape[0] <= 1:\n            #ctrl, invalid = validate_row(group.iloc[0], ctrl, invalid, max_year, disch_col, valid_col, gap)   # A group with 1 row has no readmission; goes to ctrl\n            ctrl = ctrl.append(group.iloc[0])\n        else:\n            for idx in range(group.shape[0]-1):\n                visit_time = group.iloc[idx][disch_col]  # For each index (a unique hadm_id), get its timestamp\n                if group.loc[\n                    (group[admit_col] > visit_time) &    # Readmissions must come AFTER the current timestamp\n                    (group[admit_col] - visit_time <= gap)   # Distance between a timestamp and readmission must be within gap\n                    ].shape[0] >= 1:                # If ANY rows meet above requirements, a readmission has occurred after that visit\n\n                    case = case.append(group.iloc[idx])\n                else:\n                    # If no readmission is found, only add to ctrl if prediction window is guaranteed to be within the\n                    # time range of the dataset (2008-2019). Visits with prediction windows existing in potentially out-of-range\n                    # dates (like 2018-2020) are excluded UNLESS the prediction window takes place the same year as the visit,\n                    # in which case it is guaranteed to be within 2008-2019\n\n                    ctrl = ctrl.append(group.iloc[idx])\n\n            #ctrl, invalid = validate_row(group.iloc[-1], ctrl, invalid, max_year, disch_col, valid_col, gap)  # The last hadm_id datewise is guaranteed to have no readmission logically\n            ctrl = ctrl.append(group.iloc[-1])\n            #print(f\"[ {gap.days} DAYS ] {case.shape[0] + ctrl.shape[0]}/{df.shape[0]} {visit_col}s processed\")\n\n    print(\"[ READMISSION LABELS FINISHED ]\")\n    return case, ctrl, invalid\n\ndef partition_by_mort(df:pd.DataFrame, group_col:str, visit_col:str, admit_col:str, disch_col:str, death_col:str):\n    \"\"\"Applies labels to individual visits according to whether or not a death has occurred within\n    the times of the specified admit_col and disch_col\"\"\"\n\n    invalid = df.loc[(df[admit_col].isna()) | (df[disch_col].isna())]\n\n    cohort = df.loc[(~df[admit_col].isna()) & (~df[disch_col].isna())]\n    \n    cohort['label']=0\n    #cohort=cohort.fillna(0)\n    pos_cohort=cohort[~cohort[death_col].isna()]\n    neg_cohort=cohort[cohort[death_col].isna()]\n    neg_cohort=neg_cohort.fillna(0)\n    pos_cohort=pos_cohort.fillna(0)\n    pos_cohort[death_col] = pd.to_datetime(pos_cohort[death_col])\n\n    pos_cohort['label'] = np.where((pos_cohort[death_col] >= pos_cohort[admit_col]) & (pos_cohort[death_col] <= pos_cohort[disch_col]),1,0)\n    \n    pos_cohort['label'] = pos_cohort['label'].astype(\"Int32\")\n    cohort=pd.concat([pos_cohort,neg_cohort], axis=0)\n    cohort=cohort.sort_values(by=[group_col,admit_col])\n    #print(\"cohort\",cohort.shape)\n    print(\"[ MORTALITY LABELS FINISHED ]\")\n    return cohort, invalid\n\ndef get_case_ctrls(df:pd.DataFrame, gap:int, group_col:str, visit_col:str, admit_col:str, disch_col:str, valid_col:str, death_col:str, use_mort=False,use_admn=False,use_los=False) -> pd.DataFrame:\n    \"\"\"Handles logic for creating the labelled cohort based on arguments passed to extract().\n\n    Parameters:\n    df: dataframe with patient data\n    gap: specified time interval gap for readmissions\n    group_col: patient identifier to group patients (normally subject_id)\n    visit_col: visit identifier for individual patient visits (normally hadm_id or stay_id)\n    admit_col: column for visit start date information (normally admittime or intime)\n    disch_col: column for visit end date information (normally dischtime or outtime)\n    valid_col: generated column containing a patient's year that corresponds to the 2017-2019 anchor time range\n    dod_col: Date of death column\n    \"\"\"\n\n    case = None  # hadm_ids with readmission within the gap period\n    ctrl = None   # hadm_ids without readmission within the gap period\n    invalid = None    # hadm_ids that are not considered in the cohort\n\n    if use_mort:\n        return partition_by_mort(df, group_col, visit_col, admit_col, disch_col, death_col)\n    elif use_admn:\n        gap = datetime.timedelta(days=gap)\n        # transform gap into a timedelta to compare with datetime columns\n        case, ctrl, invalid = partition_by_readmit(df, gap, group_col, visit_col, admit_col, disch_col, valid_col)\n\n        # case hadm_ids are labelled 1 for readmission, ctrls have a 0 label\n        case['label'] = np.ones(case.shape[0]).astype(int)\n        ctrl['label'] = np.zeros(ctrl.shape[0]).astype(int)\n\n        return pd.concat([case, ctrl], axis=0), invalid\n    elif use_los:\n        return partition_by_los(df, gap, group_col, visit_col, admit_col, disch_col, death_col)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.881999Z","iopub.status.idle":"2024-09-09T14:54:20.882498Z","shell.execute_reply.started":"2024-09-09T14:54:20.882245Z","shell.execute_reply":"2024-09-09T14:54:20.882269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [group_col, visit_col, admit_col, disch_col, 'Age','gender','ethnicity','insurance','label']\n\nif use_mort:\n    cols.append(death_col)\n    cohort, invalid = get_case_ctrls(pts, None, group_col, visit_col, admit_col, disch_col,'min_valid_year', death_col, use_mort=True,use_admn=False,use_los=False)\nelif use_admn:\n    interval = time\n    cohort, invalid = get_case_ctrls(pts, interval, group_col, visit_col, admit_col, disch_col,'min_valid_year', death_col, use_mort=False,use_admn=True,use_los=False)\nelif use_los:\n    cohort, invalid = get_case_ctrls(pts, los, group_col, visit_col, admit_col, disch_col,'min_valid_year', death_col, use_mort=False,use_admn=False,use_los=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.884052Z","iopub.status.idle":"2024-09-09T14:54:20.884538Z","shell.execute_reply.started":"2024-09-09T14:54:20.884278Z","shell.execute_reply":"2024-09-09T14:54:20.884314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_ICU:\n    cols.append(adm_visit_col)\nprint(cohort.info())","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.885811Z","iopub.status.idle":"2024-09-09T14:54:20.886260Z","shell.execute_reply.started":"2024-09-09T14:54:20.886030Z","shell.execute_reply":"2024-09-09T14:54:20.886061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cohort=cohort.rename(columns={\"race\":\"ethnicity\"})\nprint(cohort[cols].info())","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.888183Z","iopub.status.idle":"2024-09-09T14:54:20.888680Z","shell.execute_reply.started":"2024-09-09T14:54:20.888423Z","shell.execute_reply":"2024-09-09T14:54:20.888445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cohort.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.890290Z","iopub.status.idle":"2024-09-09T14:54:20.890770Z","shell.execute_reply.started":"2024-09-09T14:54:20.890544Z","shell.execute_reply":"2024-09-09T14:54:20.890567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cohort[cols].head(5)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.892722Z","iopub.status.idle":"2024-09-09T14:54:20.893318Z","shell.execute_reply.started":"2024-09-09T14:54:20.893013Z","shell.execute_reply":"2024-09-09T14:54:20.893043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary = \"\\n\".join([\n    f\"{label} FOR ICU DATA\",\n    f\"# Admission Records: {cohort.shape[0]}\",\n    f\"# Patients: {cohort[group_col].nunique()}\",\n    f\"# Positive cases: {cohort[cohort['label']==1].shape[0]}\",\n    f\"# Negative cases: {cohort[cohort['label']==0].shape[0]}\"\n])\n\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.895464Z","iopub.status.idle":"2024-09-09T14:54:20.895931Z","shell.execute_reply.started":"2024-09-09T14:54:20.895722Z","shell.execute_reply":"2024-09-09T14:54:20.895745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_file_path = f'{\"mimic_iv_classification_regression_tasks\"}.csv'\ncohort[cols].to_csv(csv_file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.897643Z","iopub.status.idle":"2024-09-09T14:54:20.898061Z","shell.execute_reply.started":"2024-09-09T14:54:20.897855Z","shell.execute_reply":"2024-09-09T14:54:20.897877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from datasets import Dataset\n\n# ds = Dataset.from_pandas(pd.read_csv(csv_file_path))\n# ds.push_to_hub(os.getenv('DATASET'))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:54:20.899677Z","iopub.status.idle":"2024-09-09T14:54:20.900271Z","shell.execute_reply.started":"2024-09-09T14:54:20.899965Z","shell.execute_reply":"2024-09-09T14:54:20.899997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledgements\n\n* https://github.com/healthylaife/MIMIC-IV-Data-Pipeline","metadata":{}}]}