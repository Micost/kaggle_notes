{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Introduction\n\nThis note will create dataset.\n\n# Login Huggingface","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_W\")\n\nlogin(token = hf_token)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate dataset ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport random\n\ndef generate_dataset(num_samples):\n    \"\"\"Generates a dataset of database operations and corresponding SQL statements.\n\n    Args:\n        num_samples: The number of samples to generate.\n\n    Returns:\n        A list of dictionaries, where each dictionary contains an \"input\" (JSON string representing the database operation) and an \"output\" (SQL string).\n    \"\"\"\n    dataset = []\n    for _ in range(num_samples):\n        # Randomly choose an action type\n        action = random.choice([\"query\", \"insert\", \"update\", \"delete\"])\n\n        # Generate a table name\n        table = random.choice([\"users\", \"products\", \"orders\", \"customers\", \"employees\", \"books\", \"sales\"])\n\n        input_data = {\"action\": action, \"table\": table}\n        output_sql = \"\"\n\n        if action == \"query\":\n            # Randomly choose columns to query\n            columns = random.sample([\"*\"] + get_table_columns(table), random.randint(1, len(get_table_columns(table)) + 1))\n            input_data[\"columns\"] = columns\n\n            # Generate a WHERE clause\n            where_clause = generate_where_clause(table)\n            if where_clause:\n                input_data[\"where\"] = where_clause\n\n            # Generate a JOIN clause (simplified for Kaggle example)\n            if random.random() < 0.3 and table == \"employees\": # 30% chance to generate a JOIN, only for employees table in this example\n                join_data = generate_join_clause(table)\n                if join_data:\n                    input_data[\"join\"] = join_data\n\n            output_sql = generate_select_sql(table, columns, where_clause, join_data)\n\n        elif action == \"insert\":\n            # Generate data for insertion\n            data = generate_insert_data(table)\n            input_data[\"data\"] = data\n            output_sql = generate_insert_sql(table, data)\n\n        elif action == \"update\":\n            # Generate data for update\n            data = generate_update_data(table)\n            input_data[\"data\"] = data\n\n            # Generate a WHERE clause\n            where_clause = generate_where_clause(table)\n            if where_clause:\n                input_data[\"where\"] = where_clause\n            output_sql = generate_update_sql(table, data, where_clause)\n\n        elif action == \"delete\":\n            # Generate a WHERE clause\n            where_clause = generate_where_clause(table)\n            if where_clause:\n                input_data[\"where\"] = where_clause\n            output_sql = generate_delete_sql(table, where_clause)\n\n        dataset.append({\"input\": json.dumps(input_data), \"output\": output_sql})\n    return dataset\n\n\ndef get_table_columns(table):\n    # Simplified columns for Kaggle demo\n    columns = {\n        \"users\": [\"id\", \"name\", \"email\", \"age\"],\n        \"products\": [\"id\", \"name\", \"price\", \"category\"],\n        \"orders\": [\"order_id\", \"status\", \"customer_id\"],\n        \"customers\": [\"customer_id\", \"name\", \"country\"],\n        \"employees\": [\"id\", \"name\", \"salary\", \"department_id\"],\n        \"books\": [\"title\", \"author\", \"publication_year\"],\n        \"sales\": [\"order_date\", \"amount\"]\n    }\n    return columns.get(table, [])\n\n\ndef generate_where_clause(table):\n    columns = get_table_columns(table)\n    if not columns:\n        return None\n\n    column = random.choice(columns)\n    operator = random.choice([\"=\", \">\", \"<\", \">=\", \"<=\", \"!=\"])\n    value = generate_value_for_column(column)  # Use the improved value generation\n\n    return f\"{column} {operator} {value}\"\n\ndef generate_join_clause(table):\n    if table == \"employees\":\n        return {\"table\": \"departments\", \"on\": \"employees.department_id = departments.id\", \"columns\": [\"department_name\"]}\n    return None\n\n\ndef generate_value_for_column(column):\n    # More diverse value generation\n    value_types = {\n        \"id\": random.randint(1, 100),\n        \"age\": random.randint(18, 65),\n        \"price\": round(random.uniform(1.0, 100.0), 2),\n        \"salary\": random.randint(30000, 100000),\n        \"order_id\": random.randint(1000, 9999),\n        \"customer_id\": random.randint(100, 999),\n        \"amount\": round(random.uniform(10.0, 1000.0), 2),\n        \"name\": random.choice([\"Alice\", \"Bob\", \"Charlie\", \"David\"]),\n        \"email\": lambda: f\"{random.choice(['test', 'example'])}@{random.choice(['gmail', 'yahoo'])}.com\",\n        \"category\": random.choice([\"Electronics\", \"Books\", \"Clothing\"]),\n        \"status\": random.choice([\"Pending\", \"Shipped\", \"Delivered\"]),\n        \"country\": random.choice([\"USA\", \"Canada\", \"UK\"]),\n        \"title\": random.choice([\"The Hitchhiker's Guide to the Galaxy\", \"Pride and Prejudice\"]),\n        \"author\": random.choice([\"Douglas Adams\", \"Jane Austen\"]),\n        \"publication_year\": random.randint(1900, 2023),\n        \"order_date\": lambda: f\"'{random.randint(2020, 2023)}-{random.randint(1, 12):02}-{random.randint(1, 28):02}'\",\n        \"department_id\": random.randint(1, 5) # Example for department_id\n    }\n\n    if column in value_types:\n        if callable(value_types[column]):\n            return value_types[column]()\n        else:\n            return f\"'{value_types[column]}'\" if isinstance(value_types[column], str) else str(value_types[column])\n    else:\n      return f\"'{random.choice(['value1', 'value2', 'value3'])}'\"\n\n\n\n# ... (rest of the functions: generate_insert_data, generate_update_data, generate_select_sql, generate_insert_sql, generate_update_sql, generate_delete_sql remain the same)\n\n\n# Generate the dataset and print it (or save to a file for Kaggle)\ndataset = generate_dataset(20) # Increased to 20 for more data\nprint(json.dumpsdataset, indent=4))  # Nicely formatted JSON output\n\n# To save to a JSON file (Kaggle-friendly):\n# with open(\"dataset.json\", \"w\") as f:\n#     json.dump(dataset, f, indent=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}