{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5831d005",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003326,
     "end_time": "2024-09-08T07:39:32.768390",
     "exception": false,
     "start_time": "2024-09-08T07:39:32.765064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbe035",
   "metadata": {
    "papermill": {
     "duration": 0.002519,
     "end_time": "2024-09-08T07:39:32.773762",
     "exception": false,
     "start_time": "2024-09-08T07:39:32.771243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a sample note about how to evaluate language model which is directly copied from Aisuko's note \"Evaluating language models \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301f4c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T07:39:32.780534Z",
     "iopub.status.busy": "2024-09-08T07:39:32.780138Z",
     "iopub.status.idle": "2024-09-08T07:39:32.785202Z",
     "shell.execute_reply": "2024-09-08T07:39:32.784192Z"
    },
    "papermill": {
     "duration": 0.010736,
     "end_time": "2024-09-08T07:39:32.787138",
     "exception": false,
     "start_time": "2024-09-08T07:39:32.776402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q lm-eval==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ad4bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T07:39:32.793675Z",
     "iopub.status.busy": "2024-09-08T07:39:32.793383Z",
     "iopub.status.idle": "2024-09-08T07:40:20.348193Z",
     "shell.execute_reply": "2024-09-08T07:40:20.347072Z"
    },
    "papermill": {
     "duration": 47.560981,
     "end_time": "2024-09-08T07:40:20.350864",
     "exception": false,
     "start_time": "2024-09-08T07:39:32.789883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lm-evaluation-harness'...\r\n",
      "remote: Enumerating objects: 40293, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (622/622), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (398/398), done.\u001b[K\r\n",
      "remote: Total 40293 (delta 323), reused 486 (delta 223), pack-reused 39671 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (40293/40293), 27.00 MiB | 20.88 MiB/s, done.\r\n",
      "Resolving deltas: 100% (28252/28252), done.\r\n",
      "/kaggle/working/lm-evaluation-harness\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
    "%cd lm-evaluation-harness\n",
    "!pip install --quiet -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2c5c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T07:40:20.364903Z",
     "iopub.status.busy": "2024-09-08T07:40:20.363997Z",
     "iopub.status.idle": "2024-09-08T07:40:21.400475Z",
     "shell.execute_reply": "2024-09-08T07:40:21.399445Z"
    },
    "papermill": {
     "duration": 1.045459,
     "end_time": "2024-09-08T07:40:21.402656",
     "exception": false,
     "start_time": "2024-09-08T07:40:20.357197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Evaluating allenai Meta-Llama-3.1-8B-Instruct\"\n",
    "os.environ[\"WANDB_NAME\"] = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "os.environ[\"MODEL_NAME\"] = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "os.environ[\"DATASET\"] = \"HuggingFaceH4/ultrafeedback_binarized\"\n",
    "\n",
    "login(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143d6076",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-09-08T07:40:21.414939Z",
     "iopub.status.busy": "2024-09-08T07:40:21.414176Z",
     "iopub.status.idle": "2024-09-08T07:40:21.418282Z",
     "shell.execute_reply": "2024-09-08T07:40:21.417411Z"
    },
    "papermill": {
     "duration": 0.012338,
     "end_time": "2024-09-08T07:40:21.420230",
     "exception": false,
     "start_time": "2024-09-08T07:40:21.407892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!lm_eval --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2536a3ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T07:40:21.432120Z",
     "iopub.status.busy": "2024-09-08T07:40:21.431373Z",
     "iopub.status.idle": "2024-09-08T07:40:57.002930Z",
     "shell.execute_reply": "2024-09-08T07:40:57.001723Z"
    },
    "papermill": {
     "duration": 35.580028,
     "end_time": "2024-09-08T07:40:57.005492",
     "exception": false,
     "start_time": "2024-09-08T07:40:21.425464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\r\n",
      "    response.raise_for_status()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 1024, in raise_for_status\r\n",
      "    raise HTTPError(http_error_msg, response=self)\r\n",
      "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 402, in cached_file\r\n",
      "    resolved_file = hf_hub_download(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\r\n",
      "    return fn(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1240, in hf_hub_download\r\n",
      "    return _hf_hub_download_to_cache_dir(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1347, in _hf_hub_download_to_cache_dir\r\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1854, in _raise_on_head_call_error\r\n",
      "    raise head_call_error\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1751, in _get_metadata_or_catch_error\r\n",
      "    metadata = get_hf_file_metadata(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\r\n",
      "    return fn(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1673, in get_hf_file_metadata\r\n",
      "    r = _request_wrapper(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 376, in _request_wrapper\r\n",
      "    response = _request_wrapper(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 400, in _request_wrapper\r\n",
      "    hf_raise_for_status(response)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 321, in hf_raise_for_status\r\n",
      "    raise GatedRepoError(message, response) from e\r\n",
      "huggingface_hub.utils._errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-66dd5506-1e5d756d62146d644b903acf;2596278e-70db-49e1-bd52-119cc3d58271)\r\n",
      "\r\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json.\r\n",
      "Your request to access model meta-llama/Meta-Llama-3.1-8B-Instruct is awaiting a review from the repo authors.\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/lm_eval\", line 8, in <module>\r\n",
      "    sys.exit(cli_evaluate())\r\n",
      "  File \"/kaggle/working/lm-evaluation-harness/lm_eval/__main__.py\", line 382, in cli_evaluate\r\n",
      "    results = evaluator.simple_evaluate(\r\n",
      "  File \"/kaggle/working/lm-evaluation-harness/lm_eval/utils.py\", line 397, in _wrapper\r\n",
      "    return fn(*args, **kwargs)\r\n",
      "  File \"/kaggle/working/lm-evaluation-harness/lm_eval/evaluator.py\", line 201, in simple_evaluate\r\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\r\n",
      "  File \"/kaggle/working/lm-evaluation-harness/lm_eval/api/model.py\", line 147, in create_from_arg_string\r\n",
      "    return cls(**args, **args2)\r\n",
      "  File \"/kaggle/working/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 161, in __init__\r\n",
      "    self._get_config(\r\n",
      "  File \"/kaggle/working/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 499, in _get_config\r\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 976, in from_pretrained\r\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py\", line 632, in get_config_dict\r\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\r\n",
      "    resolved_config_file = cached_file(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 420, in cached_file\r\n",
      "    raise EnvironmentError(\r\n",
      "OSError: You are trying to access a gated repo.\r\n",
      "Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.\r\n",
      "403 Client Error. (Request ID: Root=1-66dd5506-1e5d756d62146d644b903acf;2596278e-70db-49e1-bd52-119cc3d58271)\r\n",
      "\r\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json.\r\n",
      "Your request to access model meta-llama/Meta-Llama-3.1-8B-Instruct is awaiting a review from the repo authors.\r\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=${MODEL_NAME} \\\n",
    "    --tasks mmlu \\\n",
    "    --device cuda:0 \\\n",
    "    --num_fewshot 0 \\\n",
    "    --batch_size 4 \\\n",
    "    --output_path results \\\n",
    "    --use_cache True\\\n",
    "    --log_samples \\\n",
    "    --limit 10 \\\n",
    "#     --hf_hub_log_args hub_results_org=aisuko,hub_repo_name=eval-smolLM-135M,push_results_to_hub=True,push_samples_to_hub=True,public_repo=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afa175",
   "metadata": {
    "papermill": {
     "duration": 0.005237,
     "end_time": "2024-09-08T07:40:57.016381",
     "exception": false,
     "start_time": "2024-09-08T07:40:57.011144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Related issues\n",
    "\n",
    "* https://github.com/EleutherAI/lm-evaluation-harness/issues/2263"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 87.229075,
   "end_time": "2024-09-08T07:40:57.340531",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-08T07:39:30.111456",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
